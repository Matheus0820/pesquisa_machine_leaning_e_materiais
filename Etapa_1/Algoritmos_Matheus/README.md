# Desafio: ImplementaÃ§Ã£o de Kâ€‘Means em Python
Este repositÃ³rio contÃ©m o notebook **desafio_gabarito.ipynb**, que apresenta uma implementaÃ§Ã£o do algoritmo de agrupamento **Kâ€‘Means** do zero, usando apenas bibliotecas bÃ¡sicas em Python.

## ğŸ“ VisÃ£o geral do conteÃºdo
- `desafio_gabarito.ipynb`: Notebook com o passoâ€‘aâ€‘passo da implementaÃ§Ã£o:
  1. Carregamento dos dados (atributos `x` e `y`)
  2. InicializaÃ§Ã£o dos centrÃ³ides
  3. CÃ¡lculo da matriz de distÃ¢ncias dos pontos aos centrÃ³ides
  4. AtribuiÃ§Ã£o de cada ponto ao cluster mais prÃ³ximo
  5. ReavaliaÃ§Ã£o e atualizaÃ§Ã£o dos centrÃ³ides
  6. CritÃ©rio de parada (quando os centrÃ³ides deixam de mudar ou nÃºmero mÃ¡ximo de iteraÃ§Ãµes)
  7. VisualizaÃ§Ã£o grÃ¡fica dos clusters resultantes

## ğŸ§® Sobre o algoritmo Kâ€‘Means
O Kâ€‘Means Ã© um mÃ©todo de aprendizado nÃ£o supervisionado para partiÃ§Ã£o de dados em k clusters. A ideia central:
- Definir k centrÃ³ides (inicialmente de forma arbitrÃ¡ria ou aleatÃ³ria)
- Repetir atÃ© convergÃªncia:
  - Atribuir cada ponto ao centrÃ³ide mais prÃ³ximo
  - Recalcular os centrÃ³ides como as mÃ©dias dos pontos de cada cluster
- Parar quando os centrÃ³ides nÃ£o mudam ou mudam pouco

A implementaÃ§Ã£o neste notebook mostra manualmente essas etapas para fins didÃ¡ticos.

## ğŸ›  Como usar
1. Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/Matheus0820/pesquisa_machine_leaning_e_materiais.git
   ```
2. Navegue atÃ© a pasta:
   ```bash
   cd pesquisa_machine_leaning_e_materiais/Etapa_1/Algoritmos_Matheus/
   ```
3. Abra o notebook `desafio_gabarito.ipynb` no Jupyter Notebook, JupyterLab ou VSâ€¯Code com extensÃ£o de notebooks.
4. Verifique as bibliotecas necessÃ¡rias (por exemplo, `numpy`, `pandas`, `matplotlib`) e execute as cÃ©lulas sequencialmente.
5. Observe os resultados e o grÃ¡fico final que visualiza os clusters formados.

## âœ… Pontos de atenÃ§Ã£o
- A inicializaÃ§Ã£o dos centrÃ³ides influencia bastante a convergÃªncia e a qualidade final do agrupamento.
- Deve-se garantir que nenhum cluster fique vazio (ou seja, sem pontos atribuÃ­dos), o que pode levar a cÃ¡lculos de mÃ©dias invÃ¡lidas (NaN).
- Ã‰ recomendado definir um critÃ©rio de parada: por exemplo, mudanÃ§a mÃ­nima entre centrÃ³ides ou nÃºmero mÃ¡ximo de iteraÃ§Ãµes.
- O cÃ³digo pode ser adaptado para mais de 2 dimensÃµes ou para outro nÃºmero de clusters (alÃ©m de 3).

## ğŸ§­ Melhorias futuras
- Implementar o mÃ©todo de inicializaÃ§Ã£o **Kâ€‘Means++** para escolher centrÃ³ides inicializados mais inteligentemente.
- Permitir a entrada de dados com mais variÃ¡veis (multidimensionais).
- Incorporar mÃ©tricas de avaliaÃ§Ã£o (como inÃ©rcia, silhueta) para medir a qualidade do agrupamento.
- Tornar o algoritmo mais modular, aceitÃ¡vel para quaisquer k e qualquer dataset, com validaÃ§Ã£o de entrada.

## ğŸ“Š Resultados

ApÃ³s executar o algoritmo K-Means implementado neste notebook, obtemos a seguinte visualizaÃ§Ã£o dos clusters e centrÃ³ides:

![Clusters e Centroides](resultado_algoritmo_kmeans.png)

- Cada ponto colorido representa um elemento do dataset atribuÃ­do a um cluster especÃ­fico:
  - **Azul** â†’ Cluster 1
  - **Verde** â†’ Cluster 2
  - **Vermelho** â†’ Cluster 3
- Cada estrela escura representa o **centrÃ³ide** correspondente de cada cluster.
- Ã‰ possÃ­vel observar que os pontos foram agrupados corretamente em torno de seus centrÃ³ides, demonstrando a eficÃ¡cia do algoritmo.



## ğŸ“ LicenÃ§a
Este projeto estÃ¡ aberto para uso educacional e experimental. Sintaâ€‘se Ã  vontade para copiar, modificar e aprender com o conteÃºdo. Caso reutilize ou publique, agradeceâ€‘se manter a atribuiÃ§Ã£o ao autor original.
